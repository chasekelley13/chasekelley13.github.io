When scheduling my fall 2024 courses, I selected Introduction to Digital Humanities and Books in America with little understanding of their correlation. As the semester has progressed, I am blissfully in awe of the courses’ intersection, weaving the materiality of humanities with digital modes and innovation. From analyzing tangible 18th-century books to digital datasets with hundreds of points, this semester has intertwined multidimensional elements of the humanities, augmenting my understanding. This brief essay will dissect motifs from Introduction to Digital Humanities and assess their intersection with Giorgia Lupi’s Finding Humanity in Data and Katherine Hepworth’s Racism in the Machine: Visualization Ethics in Digital Humanities Projects.

Finding Humanity in Data is a talk by Giorgia Lupi that seeks to redefine data for her audience. She begins by asserting that data does not exist. She, instead, contends that it is an instrument to record patterns. An abstraction of our reality, but it is not real. Lupi uses her work for Corriere della Sera, a notable Italian newspaper, as evidence. During her tenure, Lupi created over forty visualizations to contextualize nuanced datasets. Each visual was different, complex, and deviated from a simple pie chart or graph. She found readers took time to understand the visuals, deepening their understanding of multidimensional issues. Beyond her work at Corriere della Sera, Lupi started a self-initiated project named “Dear Data,” which sought to create a connection with London-based information designer Stephanie, who she had only met twice previously. This project involved each designer sharing a piece of data per week via mailed documents. Data fell under many classifications, from grocery lists to thank-you letters. Through the project, the pair grew close while creating a tangible collection of how data tells a multifaceted narrative. 

Finding Humanity in Data themes emerged throughout our course. Her work on Corriere della Sera reminded me of our work on The Umpire, as the data we analyzed were real stories and experiences. When looking at spreadsheets, it is easy to ignore the enormity behind the various points populated on a page. Yet, each column represents a specific pocket of life from the prison. Being conscious that humans drive data is a pivotal takeaway I have gathered from this course. 

Lupi’s work on “Dear Data” reminded me of our visit to the Kislak Center. At Kislak, I assessed an early American book populated with charts. These charts had colorful markings and symbols filling each box. We poured through the pages, attempting to attach meaning to each color and symbol. In the end, we realized the book was a visual representation of the bible, with each box and symbol representing different years and events. The unorthodox display of data made us reconsider how modes vary and reinforced the narrative power of visuals. 

Katherine Hepworth’s Racism in the Machine: Visualization Ethics in Digital Humanities Projects examines how digital visualizations are bias-laden. She begins using Microsoft’s AI chatbot @TayTweets as a case study. @TayTweets was a programmed chatbot that could respond to Twitter users, creating natural responses, jokes, and even memes. When the chatbot launched on Twitter, it was seemingly successful, replying to users with witty and appropriate remarks. However, within 16 hours, the chatbot had to be taken down following a spur of racist tweets and replies. Hepworth explains, “Microsoft’s designers had a blind spot about the depth and breadth of American racism, which allowed TayTweets to replicate deep-seated preconceptions and prejudices without critically examining them” (Hepworth). Hepworth continues with an analysis of two maps illustrating the frequency of public lynchings across the U.S. between 1835 and 1964. The first map filled in states with shades of red to demonstrate frequency. The second map incorporated each lynching as a data point and used different color points to represent years. The second design was far more comprehensive, allowing the reader to see what years lynchings were common and identify specific areas where they occurred. Hepworth’s piece demonstrates how faulty or unintentional design can change the perception of data and yield negative results, informing the literature of design’s causational effect of bias-laden conclusions. 

Hepworth’s piece had a myriad of intersections with our course. Her analysis of maps reminded me of our examination of metadata. In lecture, we saw how unrepresentative markings complicated results, with faulty tags burying digital pieces in the archives. This demonstration broadcasted a real-time example of why being thorough and thoughtful is paramount in digital humanities work. Professor Porter’s visit reminded me of the @TayTweets example because he flagged the daunting capacities of AI. While there is so much potential, caution is necessary, as a lapse in attention can cause digital disasters.

Ultimately, the digital age has presented humanities with an incredible opportunity to innovate and expand. It is up to us to ensure that intentional design and the narrative nature of data are not disregarded. 

Sources: 
https://www.youtube.com/watch?v=IYRhCZ0vvFQ 
http://digitalhumanities.org:8081/dhq/vol/12/4/000408/000408.html 
